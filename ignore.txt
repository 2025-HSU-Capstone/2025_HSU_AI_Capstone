Cam->>FastAPI: 이미지 업로드 요청
  FastAPI->>Model: 이미지 전송 및 감지 요청
  Model-->>FastAPI: 감지된 재료 + bbox JSON 반환
  FastAPI->>FastAPI: 반환된 JSON → 내부에서 /detect 로직 실행 (직접 함수 호출)
  FastAPI->>DB: 식재료 + bbox 저장


  ✅ 모델을 호출하는 라우터 안에서,
모델의 응답(JSON)을 받은 다음에 바로 process_detection() 함수를 호출하면 돼.

그럼 process_detection()은 어디서 실행돼야 해?
👉 정답:
문이 열릴 때 트리거 되는 "전용 라우터" 안에서 실행돼야 해.
/trigger/detect 라우터
@router.post("/trigger/detect")
def run_detection_trigger(db: Session = Depends(get_db)):
    # 1. 카메라 → 이미지 촬영
    image_path, timestamp = capture_image()

    # 2. 객체 탐지 모델에 이미지 전송
    result = call_detection_model(image_path)

    # 3. 모델이 반환한 감지 결과를 payload로 가공
    detect_payload = DetectRequest(
        image_filename=image_path.name,
        captured_at=timestamp,
        detected_items=result["detected_items"]
    )

    # 4. 감지 결과 DB 저장
    return process_detection(detect_payload, db)



    

프론트 → 백엔드로 전달할 때는?
✔ 그 문장을 JSON 포맷으로 싸서 보내줘야 FastAPI가 이해할 수 있어

백엔드 → 모델 서버 요청 시
보통은 requests.post()로 모델 서버에 요청을 보내고,
내용은 JSON 형식으로 묶어서 전송해.

--흐름도--
[1] /trigger/detect
    → 더미 이미지 캡처 + 감지 모델 호출 (모델은 임시 JSON 반환)
    → 감지 결과(DB에 삽입): FridgeImage + FoodItem + FoodLog + DetectedBBox

[2] /generate_recipe
    → 감지된 FoodItem들 기반 레시피 생성 (모델 응답 시뮬레이터 사용)
    → 생성된 레시피 DB 저장: Recipe + RecipeIngredient + RecipeImage

[3] /recipe/bbox
    → 가장 최신 Recipe의 재료와 일치하는 DetectedBBox를 최신 이미지 기준으로 필터링
    → 이미지 파일명 + bbox 리스트 반환